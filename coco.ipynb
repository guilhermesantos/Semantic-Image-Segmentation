{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import os\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In order to proceed with dataset creation, you should download COCO 2014 Train/Val annotations (241mb).  \n",
    "The instructions are for Ubuntu and require wget and unzip. It works on bash Windows as well.  \n",
    "wget --directory-prefix=downloads http://images.cocodataset.org/annotations/annotations_trainval2014.zip  \n",
    "mkdir -p dataset/annotations  \n",
    "unzip downloads/annotations_trainval2014.zip -d dataset/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'downloads/dataset/annotations/instances_train2014.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-04a4a086002d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train2014'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mannFile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'downloads/dataset/annotations/instances_{}.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcoco\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOCO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/pycocotools-2.0-py3.7-linux-x86_64.egg/pycocotools/coco.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading annotations into memory...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annotation file format {} not supported'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done (t={:0.2f}s)'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'downloads/dataset/annotations/instances_train2014.json'"
     ]
    }
   ],
   "source": [
    "# initialize COCO api to handle instance annotations\n",
    "dataType='train2014'\n",
    "annFile='downloads/dataset/annotations/instances_{}.json'.format(dataType)\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "COCO 2014 train annotations has 90 stuff classes and 82783 images\n",
    "The full list of classes can be obtained by calling coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image segmentation by category/obj in gray scale/RGB\n",
    "# paths\n",
    "out_dir_cat='ann/cat/'\n",
    "out_dir_obj='ann/obj/'\n",
    "out_dir_rgb_cat='ann/rgb_cat/'\n",
    "out_dir_rgb_obj='ann/rgb_obj/'\n",
    "# Set between cat and obj image creation, categories has each object related with their pixels corresponding ID,\n",
    "# obj are random coloured, making it easier for visualization\n",
    "cat_save=True\n",
    "# Set to true if you want showroom RGB images, useless for training data as\n",
    "# it's does not contains pixels corresponding categories IDs \n",
    "rgb_save=False\n",
    "# Get all imageIDs and categories\n",
    "allImgIds = coco.getImgIds()\n",
    "allImgCat=coco.cats\n",
    "# Iterate in all images notations to create segmentation the corresponding segmentation image \n",
    "for IM in range(0,len(allImgIds)):\n",
    "#     Get all image IDs\n",
    "    imgIds=coco.getImgIds(imgIds = allImgIds)\n",
    "#     Load corresponding image by it's ID\n",
    "    img = coco.loadImgs(imgIds)[IM]\n",
    "#     Get annotations by it's image's ID\n",
    "    annIds = coco.getAnnIds(imgIds=img['id'], iscrowd=None)\n",
    "#     Load annotations by it's corresponding IDs\n",
    "    anns = coco.loadAnns(annIds)\n",
    "#     Create matrix with the same size as original image to store classes in both gray and RGB scales \n",
    "    seg_imageGray=np.zeros((img['height'],img['width'])).astype(np.uint8)\n",
    "    seg_imageRGB=np.zeros((img['height'],img['width'],3)).astype(np.uint8)\n",
    "#     For each image annotation, extract their corresponding pixels objects\n",
    "# each image can have multiple annotations\n",
    "    for i in range(len(anns)):\n",
    "#         Get object mask\n",
    "        seg_image=coco.annToMask(anns[i])\n",
    "#     Check for pixels in common and remove from image as solution to overlapping images\n",
    "        seg_image=(seg_image-(seg_image&seg_imageGray))\n",
    "#     Handle the creation of RGB images, just for showroom \n",
    "        if rgb_save==True:\n",
    "#         Create a matrix with the same size as image, but with 3 channels \n",
    "            imgRGB = np.zeros((img['height'],img['width'],3))\n",
    "#     Get random values for color mask [0,1] and store objects pixels in the matrix\n",
    "            color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "            imgRGB[:,:,0]=((seg_imageGray|seg_image)==1)*color_mask[0]\n",
    "            imgRGB[:,:,1]=((seg_imageGray|seg_image)==1)*color_mask[1]\n",
    "            imgRGB[:,:,2]=((seg_imageGray|seg_image)==1)*color_mask[2]\n",
    "#             Add coloured object into the main RGB image\n",
    "            seg_imageRGB=seg_imageRGB+imgRGB\n",
    "#     save images (categories/objects and RGB/gray)\n",
    "        if cat_save==True:\n",
    "            seg_imageGray=(seg_imageGray+((seg_imageGray|seg_image)==1)*(anns[i]['category_id']+50))\n",
    "        else:\n",
    "            seg_imageGray=(seg_imageGray+((seg_imageGray|seg_image)==1)*(50+anns[i]['category_id']+(110//len(anns))*i))\n",
    "    if cat_save==True:\n",
    "        imageio.imsave(out_dir_cat+img['file_name'], seg_imageGray.astype(np.uint8))\n",
    "        if rgb_save==True:\n",
    "            imageio.imsave(out_dir_rgb_cat+img['file_name'], Norm(seg_imageRGB,0,255).astype(np.uint8))\n",
    "    else:\n",
    "        imageio.imsave(out_dir_obj+img['file_name'], seg_imageGray.astype(np.uint8))\n",
    "        if rgb_save==True:\n",
    "            imageio.imsave(out_dir_rgb_obj+img['file_name'], Norm(seg_imageRGB,0,255).astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
