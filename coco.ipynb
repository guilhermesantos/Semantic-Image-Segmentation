{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.mask import *\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In order to proceed with dataset creation, you should download COCO 2014 Train/Val annotations (241mb).  \n",
    "The instructions are for Ubuntu and require wget and unzip. It works on bash Windows as well.  \n",
    "wget --directory-prefix=downloads http://images.cocodataset.org/annotations/annotations_trainval2014.zip  \n",
    "mkdir -p dataset/annotations  \n",
    "unzip downloads/annotations_trainval2014.zip -d dataset/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=49.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api to handle instance annotations\n",
    "dataType='train2014'\n",
    "annFile='downloads/dataset/annotations/instances_{}.json'.format(dataType)\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "COCO 2014 train annotations has 90 stuff classes and 82783 images\n",
    "The full list of classes can be obtained by calling coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image segmentation by category/obj in gray scale/RGB\n",
    "def create_dataset1ch():\n",
    "    # paths\n",
    "    out_dir_cat='data/coco/ground_truth/cat/'\n",
    "    out_dir_obj='data/coco/ground_truth/obj/'\n",
    "    out_dir_rgb_cat='data/coco/ground_truth/rgb_cat/'\n",
    "    out_dir_rgb_obj='data/coco/ground_truth/rgb_obj/'\n",
    "    # Set between cat and obj image creation, categories has each object related with their pixels corresponding ID,\n",
    "    # obj are random coloured, making it easier for visualization\n",
    "    cat_save=True\n",
    "    # Set to true if you want showroom RGB images, useless for training data as\n",
    "    # it's does not contains pixels corresponding categories IDs \n",
    "    rgb_save=False\n",
    "    # Get all imageIDs and categories\n",
    "    allImgIds = coco.getImgIds()\n",
    "    allImgCat=coco.cats\n",
    "    # Iterate in all images notations to create segmentation the corresponding segmentation image \n",
    "    for IM in range(0,1):\n",
    "    #     Get all image IDs\n",
    "        imgIds=coco.getImgIds(imgIds = allImgIds)\n",
    "    #     Load corresponding image by it's ID\n",
    "        img = coco.loadImgs(imgIds)[IM]\n",
    "    #     Get annotations by it's image's ID\n",
    "        annIds = coco.getAnnIds(imgIds=img['id'], iscrowd=None)\n",
    "    #     Load annotations by it's corresponding IDs\n",
    "        anns = coco.loadAnns(annIds)\n",
    "    #     Create matrix with the same size as original image to store classes in both gray and RGB scales \n",
    "        seg_imageGray=np.zeros((img['height'],img['width'])).astype(np.uint8)\n",
    "        seg_imageRGB=np.zeros((img['height'],img['width'],3)).astype(np.uint8)\n",
    "    #     For each image annotation, extract their corresponding pixels objects\n",
    "    # each image can have multiple annotations\n",
    "        for i in range(len(anns)):\n",
    "    #         Get object mask\n",
    "            seg_image=coco.annToMask(anns[i])\n",
    "    #     Check for pixels in common and remove from image as solution to overlapping images\n",
    "            seg_image=(seg_image-(seg_image&seg_imageGray))\n",
    "    #     Handle the creation of RGB images, just for showroom \n",
    "            if rgb_save==True:\n",
    "    #         Create a matrix with the same size as image, but with 3 channels \n",
    "                imgRGB = np.zeros((img['height'],img['width'],3))\n",
    "    #     Get random values for color mask [0,1] and store objects pixels in the matrix\n",
    "                color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "                imgRGB[:,:,0]=((seg_imageGray|seg_image)==1)*color_mask[0]\n",
    "                imgRGB[:,:,1]=((seg_imageGray|seg_image)==1)*color_mask[1]\n",
    "                imgRGB[:,:,2]=((seg_imageGray|seg_image)==1)*color_mask[2]\n",
    "    #             Add coloured object into the main RGB image\n",
    "                seg_imageRGB=seg_imageRGB+imgRGB\n",
    "    #     save images (categories/objects and RGB/gray)\n",
    "            if cat_save==True:\n",
    "                seg_imageGray=(seg_imageGray+((seg_imageGray|seg_image)==1)*(anns[i]['category_id']+50))\n",
    "            else:\n",
    "                seg_imageGray=(seg_imageGray+((seg_imageGray|seg_image)==1)*(50+anns[i]['category_id']+(110//len(anns))*i))\n",
    "        if cat_save==True:\n",
    "            imageio.imsave(out_dir_cat+img['file_name'], seg_imageGray.astype(np.uint8))\n",
    "            if rgb_save==True:\n",
    "                imageio.imsave(out_dir_rgb_cat+img['file_name'], Norm(seg_imageRGB,0,255).astype(np.uint8))\n",
    "        else:\n",
    "            imageio.imsave(out_dir_obj+img['file_name'], seg_imageGray.astype(np.uint8))\n",
    "            if rgb_save==True:\n",
    "                imageio.imsave(out_dir_rgb_obj+img['file_name'], Norm(seg_imageRGB,0,255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation with n ground truth channels\n",
    "each category needs to have it's own channel, in order to archive that we will develop a new function based on the older one tha handles dataset creation (wrongly =/) with just one channel.  \n",
    "\n",
    "Steps:\n",
    "1. list every categorie available (80 categories, ranging from 1 to 90 IDs -_-)  \n",
    "2. create matrix with 90 channels\n",
    "3. on every image do:\n",
    "4. get object segmentation\n",
    "5. check it's category\n",
    "6. add it on the corresponding channel\n",
    "    * But what if we have more than one object in the same cattegory? We just need to use OR operator instead sum each object into the matrix.\n",
    "7. save matrix using np.save()\n",
    "    * if you want to see each channel, just use imageio.imsave() and don't forget to multiply it by 255 \n",
    "    \n",
    "Done that we should be able to train our network (hopefuly)\n",
    "\n",
    "## Todo:\n",
    "We need to optimize dataset storing because what we had described above takes to much space. Each numpy file takes around 20mb and we have ~80k images\n",
    "- [x] Metadata saver\n",
    "    * save each channel in csv/json/txt containing:\n",
    "        * image size\n",
    "        * cat 0\n",
    "            * ground truth of all objects labeled with the corresponding cat and compressed in just one matrix\n",
    "        * cat N\n",
    "            * only categories that has pixels > 0 \n",
    "            * we will store the hole matrix for that cat\n",
    "- [x] Metadata loader\n",
    "    * load metadata saved by metadata saver and create np.array(image size,91 channels)\n",
    "    * channel 0 should contain ground truth of all\n",
    "    * load cat N by doing array :, : , N = matrix N stored in metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image segmentation by category/obj in gray scale/RGB\n",
    "def create_datasetNch():\n",
    "    # paths\n",
    "    out_dir_cat='data/coco/ground_truth/cat/'\n",
    "    out_dir_obj='data/coco/ground_truth/obj/'\n",
    "    out_dir_rgb_cat='data/coco/ground_truth/rgb_cat/'\n",
    "    out_dir_rgb_obj='data/coco/ground_truth/rgb_obj/'\n",
    "    # Set between cat and obj image creation, categories has each object related with their pixels corresponding ID,\n",
    "    # obj are random coloured, making it easier for visualization\n",
    "    cat_save=True\n",
    "    # Set to true if you want showroom RGB images, useless for training data as\n",
    "    # it's does not contains pixels corresponding categories IDs \n",
    "    rgb_save=False\n",
    "    # Get all imageIDs and categories\n",
    "    allImgIds = coco.getImgIds()\n",
    "    allImgCat=coco.cats\n",
    "    # Iterate in all images notations to create segmentation the corresponding segmentation image \n",
    "    for IM in range(0,1):\n",
    "    #     Get all image IDs\n",
    "        imgIds=coco.getImgIds(imgIds = allImgIds)\n",
    "    #     Load corresponding image by it's ID\n",
    "        img = coco.loadImgs(imgIds)[IM]\n",
    "    #     Get annotations by it's image's ID\n",
    "        annIds = coco.getAnnIds(imgIds=img['id'], iscrowd=None)\n",
    "    #     Load annotations by it's corresponding IDs\n",
    "        anns = coco.loadAnns(annIds)\n",
    "    #     Create matrix with the same size as original image to store classes in both gray and RGB scales\n",
    "        seg_imageNch=np.zeros((img['height'],img['width'],91)).astype(np.uint8)\n",
    "        seg_imageGray=np.zeros((img['height'],img['width'])).astype(np.uint8)\n",
    "        seg_imageRGB=np.zeros((img['height'],img['width'],3)).astype(np.uint8)\n",
    "    #     For each image annotation, extract their corresponding pixels objects\n",
    "    # each image can have multiple annotations\n",
    "        for i in range(len(anns)):\n",
    "    #         Get object mask\n",
    "            seg_image=coco.annToMask(anns[i])\n",
    "#             Add object to it's corresponding channel\n",
    "            seg_imageNch[:,:,anns[i]['category_id']]=seg_imageNch[:,:,anns[i]['category_id']]|seg_image\n",
    "    #     Check for pixels in common and remove from image as solution to overlapping images\n",
    "            seg_image=(seg_image-(seg_image&seg_imageGray))\n",
    "    #     Handle the creation of RGB images, just for showroom \n",
    "            if rgb_save==True:\n",
    "    #         Create a matrix with the same size as image, but with 3 channels \n",
    "                imgRGB = np.zeros((img['height'],img['width'],3))\n",
    "    #     Get random values for color mask [0,1] and store objects pixels in the matrix\n",
    "                color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "                imgRGB[:,:,0]=((seg_imageGray|seg_image)==1)*color_mask[0]\n",
    "                imgRGB[:,:,1]=((seg_imageGray|seg_image)==1)*color_mask[1]\n",
    "                imgRGB[:,:,2]=((seg_imageGray|seg_image)==1)*color_mask[2]\n",
    "    #             Add coloured object into the main RGB image\n",
    "                seg_imageRGB=seg_imageRGB+imgRGB\n",
    "    #     save images (categories and RGB/gray)\n",
    "            seg_imageGray=(seg_imageGray+((seg_imageGray|seg_image)==1)*(anns[i]['category_id']+50))\n",
    "            seg_imageNch[:,:,0]=seg_imageGray.astype(np.uint8)\n",
    "#         for ch in range(len(allImgCat)):\n",
    "#             if np.max(seg_imageNch[:,:,ch])>0:\n",
    "#                 imageio.imsave(out_dir_cat+img['file_name']+str(ch)+'.jpg', seg_imageNch[:,:,ch]*255)\n",
    "        imageio.imsave(out_dir_cat+img['file_name'], seg_imageGray.astype(np.uint8))\n",
    "        np.save(out_dir_cat+img['file_name'],seg_imageNch,allow_pickle=False)\n",
    "        return seg_imageNch\n",
    "        if rgb_save==True:\n",
    "            imageio.imsave(out_dir_rgb_cat+img['file_name'], Norm(seg_imageRGB,0,255).astype(np.uint8))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata saver and loader\n",
    "\n",
    "\n",
    "1. createGroundTruth()  \n",
    "    * It create the image ground truth and store it in json file, this way we decreased almost 10x numpy size file\n",
    "    * shape contains np.shape()\n",
    "    * 0 is the ground truth of all category channels. \n",
    "    * N is the ground truth of each category which has any pixel > 0. N can varies from 1 to 90 \n",
    "2. saveGroundTruth()  \n",
    "    * it just save the image ground truth in json\n",
    "3. loadGroundTruth()  \n",
    "    * it load json file and return the corresponding np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGroundTruth(start,end):\n",
    "    out_dir_cat='data/coco/ground_truth/'\n",
    "    # Get all imageIDs and categories\n",
    "    allImgIds = coco.getImgIds()\n",
    "    allImgCat=coco.cats\n",
    "    #     Get all image IDs\n",
    "    imgIds=coco.getImgIds(imgIds = allImgIds)\n",
    "    for IM in range(start,end):\n",
    "    #     Load corresponding image by it's ID\n",
    "        img = coco.loadImgs(imgIds)[IM]\n",
    "        print(IM,img['id'])\n",
    "    #     Get annotations by it's image's ID\n",
    "        annIds = coco.getAnnIds(imgIds=img['id'], iscrowd=None)\n",
    "    #     Load annotations by it's corresponding IDs\n",
    "        anns = coco.loadAnns(annIds)\n",
    "    #     Create matrix with the same size as original image to store classes in both gray and RGB scales\n",
    "        seg_imageNch=np.zeros((img['height'],img['width'],91)).astype(np.uint8)\n",
    "        seg_imageGray=np.zeros((img['height'],img['width'])).astype(np.uint8)\n",
    "        for i in range(len(anns)):\n",
    "    #         Get object mask\n",
    "            seg_image=coco.annToMask(anns[i])\n",
    "#             Add object to it's corresponding channel\n",
    "            seg_imageNch[:,:,anns[i]['category_id']]=seg_imageNch[:,:,anns[i]['category_id']]|seg_image\n",
    "    #     Check for pixels in common and remove from image as solution to overlapping images\n",
    "            seg_image=(seg_image-(seg_image&seg_imageGray))\n",
    "    #     Add obj to ground truth in gray\n",
    "            seg_imageGray=(seg_imageGray+((seg_imageGray|seg_image)==1)*(anns[i]['category_id']))\n",
    "#         add ground truth of everything into channel 0\n",
    "        seg_imageNch[:,:,0]=seg_imageGray.astype(np.uint8)\n",
    "        saveGroundTruth(out_dir_cat+img['file_name'],seg_imageNch)\n",
    "\n",
    "def saveGroundTruth(name,gt):\n",
    "    data=dict()\n",
    "    width,weight,ch=gt.shape\n",
    "    data['shape']=gt.shape\n",
    "    data['0']= gt[:,:,0].tolist()\n",
    "    for i in range(1,ch):\n",
    "        if np.max(gt[:,:,i])>0:\n",
    "            data[str(i)]=gt[:,:,i].tolist()\n",
    "    with open(name+'.json', 'w') as out:  \n",
    "        json.dump(data,out)\n",
    "        out.close\n",
    "\n",
    "def loadGroundTruth(name):\n",
    "    out_dir_cat='data/coco/ground_truth/'\n",
    "    with open(out_dir_cat+name+'.json') as file:\n",
    "        j = json.load(file)\n",
    "        seg_imageNch=np.zeros(j['shape']).astype(np.uint8)\n",
    "        print(seg_imageNch.shape)\n",
    "        print(j['shape'])\n",
    "        keys=list(j.keys())\n",
    "        print(keys)\n",
    "        for i in keys[1:]:\n",
    "            seg_imageNch[:,:,int(i)]=j[i]\n",
    "        file.close()\n",
    "    return seg_imageNch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57870\n",
      "[57870, 384029, 222016, 520950, 69675]\n",
      "[102924, 118582, 290250, 290659, 290682, 290718, 290760, 290772, 290776, 1154173, 1594658, 1600168, 2128139, 2132468, 2143343, 2143738, 2190436, 423921, 1086559, 1577025, 1925582, 1926447, 1926600, 1926695, 1927036, 1928113, 1928987, 1929055, 2189534, 2189663, 2222000, 459512, 671180, 706026, 1124706, 1491871, 1492008, 1492710, 1521374, 1524774, 1865874, 1866767, 1869329, 1870788, 1871020, 1871344, 1871967, 1881923, 2095142, 2095779, 675057, 1128440, 1216611, 1499420, 1726664, 1874219, 1979799, 2106265]\n"
     ]
    }
   ],
   "source": [
    "allImgIds = coco.getImgIds()\n",
    "# createGroundTruth(0,1)\n",
    "print(allImgIds[0])\n",
    "img = coco.loadImgs(allImgIds)\n",
    "print([f['id'] for f in img[0:5]])\n",
    "annIds = coco.getAnnIds(imgIds=[f['id'] for f in img[0:5]], iscrowd=None)\n",
    "print(annIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CocoDataset class\n",
    "\n",
    "Instead of load ~5mb json file for each image ground truth, let's try working with a ~300mb unique json file from coco and build ground truth from it. We will have a huge decrease in ground truth size, but we are not sure about the performance itself as we are building it just in time of the train.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, image_dir, coco, transform):\n",
    "        self.image_dir = image_dir\n",
    "        self.coco = coco\n",
    "        self.imgs = coco.loadImgs(coco.getImgIds())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = Image.open(self.image_dir + \"\\\\\" + self.imgs[i]['file_name'])\n",
    "        image = self.transform(image)\n",
    "        image = self.pad_image(image, 700, 700)\n",
    "\n",
    "        gt = self.load_ground_truth(i)\n",
    "        gt = self.transform(np.transpose(gt, (0, 1, 2)))\n",
    "        gt = self.pad_image(gt, 700, 700)\n",
    "\n",
    "        return image, gt[1:, :, :]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def load_ground_truth(self, i):\n",
    "        annIds = self.coco.getAnnIds(imgIds=self.imgs[i]['id'], iscrowd=None)\n",
    "        anns = self.coco.loadAnns(annIds)\n",
    "        seg_imageNch = np.zeros((self.imgs[i]['height'], self.imgs[i]['width'], 91)).astype(np.uint8)\n",
    "        seg_imageGray = np.zeros((self.imgs[i]['height'], self.imgs[i]['width'])).astype(np.uint8)\n",
    "        for i in range(len(anns)):\n",
    "            seg_image = self.coco.annToMask(anns[i])\n",
    "            seg_imageNch[:, :, anns[i]['category_id']] = seg_imageNch[:, :, anns[i]['category_id']] | seg_image\n",
    "            seg_image = (seg_image - (seg_image & seg_imageGray))\n",
    "            seg_imageGray = (seg_imageGray + ((seg_imageGray | seg_image) == 1) * (anns[i]['category_id']))\n",
    "        seg_imageNch[:, :, 0] = seg_imageGray.astype(np.uint8)\n",
    "        return seg_imageNch\n",
    "\n",
    "    def pad_image(self, source, desired_height, desired_width):\n",
    "        padded_image = (-1) * torch.ones(source.shape[0], desired_height, desired_width)\n",
    "        padded_image[:, :source.size()[1], :source.size()[2]] = source\n",
    "\n",
    "        return padded_image\n",
    "\n",
    "    def collate(self, batch):\n",
    "        print('collating')\n",
    "        data = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        print('collating successful')\n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "coco_dataset = CocoDataset(\"data/coco/images\",coco, transform)\n",
    "for i in range(10):\n",
    "    coco_dataset.__getitem__(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "262145\n",
      "262146\n",
      "524291\n",
      "524297\n",
      "9\n",
      "262159\n",
      "524311\n",
      "25\n",
      "524314\n",
      "262171\n",
      "(427, 640, 91)\n",
      "[427, 640, 91]\n",
      "['shape', '0', '1', '28', '57']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb92a9ff940>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD8CAYAAACB3pQWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X/MXNV95/H3t2BMfkCMMbDGtta4cbfJVuWBfRbsslmlkDTARjWVki6oStjKqiuVbBMl2thkpU27WiQsbUMabRetU9KAlA1hnXSxKCrlVxSiEMAmYCAuxXHY+pG9ODSGOFvVtZ3v/jFnYDy+M3Pn/jznzuclPXpm7tyZOefOnc89c+6595q7IyIiafq5tgsgIiLFKcRFRBKmEBcRSZhCXEQkYQpxEZGEKcRFRBJWW4ib2dVm9qKZ7TWzLXW9j4jILLM6xomb2WnA3wDvBxaAp4Ab3P37lb+ZiMgMq6slfhmw1933ufs/AncDG2p6LxGRmXV6Ta+7Atg/cH8BuHzUzGfYYj+Tt9VUFBGR9Bzh8Kvuft6k+eoKccuYdlK/jZltAjYBnMlbudyuKvWGZz22rNTzq3LkPa+2XQQR6YCHfPv/yTNfXSG+AKwauL8SODA4g7tvA7YBnG1LS3XMxxLgEFdZqqCNkkjc6uoTfwpYa2YXmdkZwPXAjqrf5KzHlnUuNGOj5SsSt1pC3N2PAx8DHgD2APe4+wtVvofCpTla1iLxqqs7BXe/H7i/6tdVoIiIvCmpIzYV4O3RsheJUxIhrr7vOOgzEIlPEiGuERIiItlq6xOv2rRBrlZjPc56bJk2qiIRSSbEp6XQr4+CXCQenQ3xaU0TSgp8BblILBTiBaiV36MgF2mfQrwBw0HX1VAXkeYlMTqla46859U3/lKnDZJIuxTiLetCmCvIRdqjEI9E6q1zBblIOxTiEUo5zEWkWQrxiKXWOldrXKR5CvFEpBLoCnKRZinEE5RCmItIMzROvGWDLddpg3lw/phawDoISKQ5CvGIjAriPIEYW6AryCV1+7auZ83mx9suxkSlQtzMXgaOACeA4+4+b2ZLga8Bq4GXgd9098Plitkt04Zsf/68oRhboIukZN/W9Zm3+2IL9ir6xH/V3efcfT7c3wI87O5rgYfDfQnKhGqRi2O02RrWBkRSkxXasatjx+YG4M5w+07guhreIzlVXp1o2tfSjlCRyfIGeGxBXzbEHfgrM9tlZpvCtAvc/SBA+H9+1hPNbJOZ7TSzncc4WrIY8arz0nJFw7zJQFdrXLoopiA3dy/+ZLML3f2AmZ0PPAj8e2CHuy8ZmOewu58z7nXOtqV+uV1VuBwxaiu8ygR0nWXWLwGJWdFQrrN//CHfvmugm3qkUi1xdz8Q/h8C/hy4DHjFzJYDhP+HyrxHatq+qHOZ9x9sqVcdumqRSxfF0CIvPDrFzN4G/Jy7Hwm3fw34z8AO4Ebg1vD/3ioKmoKYgqqKIX5lW/VqfUsKygbx8PObHr1SpiV+AfBtM3sWeBL4C3f/S3rh/X4zewl4f7jfeTEFeF9bvwoU4JKKOlrSTbfOC7fE3X0fcHHG9L8DutXBPUaM4T2srlAdrruCW1JSV9g23RLXEZslpBDgfXkPGBq3Yg+vnEfe8+pJyyCl5SHSFQrxglINrKxWeR0tEnWpSMzq7PJo+ihPncVwBjXVV95/n1Q3eCJVqXOjoRAvaBZbmWVWRAW5xKLOQB3X4q7rfRXiJcxikA8qeiIvqc++reujGLscqzqWzZrNj78R3m0se/WJz7CzHlvGs99ZW/i5RZ836xu/Ko0KjRTOvtcVbW801RKXqezbur50i1ot8mpMGx5qpXdzQ6YQl1akFOT98Bv8a1uZMsRQ/jZVEeQxbQzUnSJT63eHVNEij6FrpUiotXmodRUhPOmqNV3vjlmz+fHObAjVEp9xZb6YVZwoK6UW+ThNtdCrfI9p+tOb1sSvnq5slNQSl6kNt+LKtszbbpGXbZV1QZ76N3HNyaxy9KeVee8YPt+6lp1a4jPurMeWRdEi6VKLPKXXjqWPvy4x1a+usqglPuOKtoDraJWVbZG3fUrQrssaCx3rMo4luLNU/d1RS1wKG2xZxNiSbuuL3MWhf6MOZplU7jZG9MS+LOHUEU9lKMRnWL/VW8VJ8avq0y66MUjhi5tlsNyx1qGKoxEnjYSZ9NpZz49t2Gdb1J0yo46859XqRzp8By7+lZeqfc0xpv1JGtOwuXEjQ2Loohguw6jyDu8ULvOZjHuPcY9Pen4KynzuE1viZvYlMztkZs8PTFtqZg+a2Uvh/zlhupnZF8xsr5ntNrNLC5UqITGMc+6ipr+QVQdnyoEyjWm7V6p6H3lTnpb4l4H/Btw1MG0L8LC732pmW8L9zcA1wNrwdzlwe/jfuElb9SplBXmMfcR9VbfCh1+7ksPyvzN5viqGntWhjvI0GWJVlb/LLedp1TmMdWJL3N2/Bfx4aPIG4M5w+07guoHpd3nPd4El4Yr3jZpmYdUZZnVcNT52bXwxx73nYJ/puH7VqsS2QSmi7DLJen7ZFnvqyzXG84lf4O4HAcL/88P0FcD+gfkWwrRGTfrAh3eG1B08MYV5na3wKk3bt57nS55CvWMKq1h2GMZSjlhVPTrFMqZ55oxmm8xsp5ntPMbRiosRp7bDvKkAL3p627bEFJxZ2g6wtt9/VhRdzkVD/JV+N0n4fyhMXwBWDcy3EjiQ9QLuvs3d5919fhGLCxYjTW0EedMt8KaDvGjd2gjwSd0/eedNVRfr1KaiQwx3ADcCt4b/9w5M/5iZ3U1vh+br/W6XrsuzYmadbwTq3wkaQ1fO8EYkT3fJxb/yUu0bg8G+8lTOoZJKOUdJvfyxmRjiZvZV4L3AMjNbAD5LL7zvMbONwN8CHw6z3w9cC+wF/h747RrKnMu4FSXrsSZGOox6jzwnkJo2iIcPYW/jS/Psd9aOHOObWpdLXnWO8x58XQWhlkHfxBB39xtGPHRVxrwO3FS2UHXKO+yp7jDPev3BMB8V2nkPrGg7wKW8SetijCGWp0xVlTm2urel04fdN9XfWWRlGvecPAFe9H2blkIZ+2Io6/A6G/tO1zZ1cdkUWQc7HeKxq2I8ewzBk7I2r1I+SZ6Qii3IptlpW+d7xWaaz2naeiUd4sMnwBl1bozhvsS8r92Eut8nlhU9prDprxMxlamr6urH12f3pmRPgFXmiK9YW19FTtCUwso8zc6+Oj+bUWWIbT2YVox94339zz7W8sVq39b18OntueZNuiWeZZqVJabWWNVn7EtZk194hUv9ql7GKW4U6ixv9C3xJj6stleKSf2Ig+OYq3pd6dbyGXVemJhoVEo9OtcSL9piLdMqn6VWclF1jp+OTSxHj87K8p51nQrxKlbatlb8PFc+ybMjd/A5qcnzi6OrQ/BSP31tU7ryeVcp+u6UvGI7B0aTZejCij1NOBetb1eWVR4xrJt16Gq9yuhMS7zJc0LXcWrMWVg5R4XorARrX1d/TUg7OtMSh2pbWikPR4u9jAotLQMZb83mx9mXc95OhTjU95M59mBMzfDyVKhJV9U9+q0z3SmDqlxguqpItUYtz6aWc2yfZWzlkfREH+JldmKV/YLoCyZ1GB5dpPVMyog+xMtKqSU97pSjsZ3zpS6pl79v2np0pd5yqjKnCMkjiRCvor9UXxKJgdbDesR0Co0yitQhiRCvSkqtcpktXQigNjVxMZdY5bk825eADwKH3P2XwrQ/AH4H+FGY7TPufn947GZgI3AC+H13f6CKglZ5druuHvTRhQ1UzBfySEWX69Y1VazveVriXwauzph+m7vPhb9+gL8buB745+E5/93MTitdygFVfcljXNGLnIq2S7oe4KPed5Y+47rF+L2uW55rbH7LzFbnfL0NwN3ufhT4oZntBS4DKl1Lq2qVj/sJ1tbKUGY0TiwG65CnXF0NsZg+ky5o+2yjsSpzsM/HzOyjwE7gU+5+GFgBfHdgnoUw7RRmtgnYBHAmby1UgKo+1K52r7SlzOlzZ42WT34K8GxFd2zeDvw8MAccBP4oTLeMeT3rBdx9m7vPu/v8IhYXLEa3u1dSpuXZjq4t97yjTmLdGDZRrkIh7u6vuPsJd/8Z8EV6XSbQa3mvGph1JXCgXBGbE/sXYNTJo2Ltsoh9eUq3pLa+VfWdLBTiZrZ84O5vAM+H2zuA681ssZldBKwFnixXxMmqDKjYV4Thi/zGGuAiZeW9wHnM63cTeZJniOFXgfcCy8xsAfgs8F4zm6PXVfIy8LsA7v6Cmd0DfB84Dtzk7ifqKXp9Yg/yvhR29MS6vyGGZRfjcomZlle2PKNTbsiYfMeY+W8BbilTqFlVx0oaw4ofa5B3TdsbpSppfclvpo7Y7CKt7Nm0XNJV5LPr0gZsWp07n7i8adaDrO0uk5iOP0jFrK+zRXQixLvwxSiz8rYdVpKfQkqq1okQF4XDrOvKRrxL+0+aalwlH+JdWXm7IMYvn36ldN+sf75J79jsyocXY/hNqwt1kDh05XvdlORb4pLftCemKvK6bZhUr663xrtct0lirntTZUs2xJv+8LoWBFWNnGg7wIfFVh5Jx7h1J+9phNvICHPPPD9Vo862pX65XXXK9C6F5igxh06XdjLBqetT3Rvmrp8fvW55ll9Vda/6s6ridBgP+fZd7j4/6XWiaonHvjJ2rTU+SSoB/sCBZzKnf+DCuZPuz9rn13VFP8tU1uu8ogrx2CkA4jEquIfnmYUgr/LShTGp8pdgbMFdZXmiCvEufsHGiW3FSkWeAB+cNyvIu6irYV5GVz/rQUkPMWzDLKwUUg2FaXllluGsfFejaomnYJa/mHn7ntsowyhNlk3qkdWtEvv3cFyvQtUbl+hCfNa6VFIxLjyHuywmBa2CtT767vTE0ArPyrI6yhVdiKdgljY0eVu+0/ZT51Um8LWx6I5Uh7tGcY1NM1tlZo+a2R4ze8HMPh6mLzWzB83spfD/nDDdzOwLZrbXzHab2aV1VyJFKayQ03Zd1FWG/t8kH7hw7qS/PFL4HPLqesMib/269Jnmkaclfhz4lLs/bWZnAbvM7EHg3wEPu/utZrYF2AJsBq6hd23NtcDlwO3hf24xt3S7uILEENZ5jCtnmVZ3zOtbHimXvWpd/H5OMrEl7u4H3f3pcPsIsAdYAWwA7gyz3QlcF25vAO7ynu8CS4YurNwJqa8s07RwZ0Gql8abtQCftfrmMdUQQzNbDVwCPAFc4O4HoRf0wPlhthXA/oGnLYRpw6+1ycx2mtnOYxydvuRSmII7W0ob5n1b11cSaCnVua+pUR+pyB3iZvZ24OvAJ9z9J+NmzZh2ygla3H2bu8+7+/wiFuctRmvWbH58ZleSWZLCEYKxni+kScNlT7kuZeUanWJmi+gF+Ffc/Rth8itmttzdD4bukkNh+gKwauDpK4EDVRW4DaNWkKJ9qbO8wtUl69dF0X7yWPvIu3T64LJi/Hzakmd0igF3AHvc/XMDD+0Abgy3bwTuHZj+0TBKZR3wer/bJTVqfaetTLdRbJ+7QktGydMSvwL4CPCcmfW/FZ8BbgXuMbONwN8CHw6P3Q9cC+wF/h747UpL3IDYvsBSXBtHmbZxWtNp1HVxEGnHxBB392+T3c8NcMpJwL13gvKbSparcUW/eLH+9G5aPxRT2WmadWKsYTF8tnUGuHTDzB6x2fWVuekwTSW8B8Ue5ApwySPKEK/jSxPLClx3OZoI0w9cOFfoRFQxBn2eHaLTnOK1qs+37V8Ako4oQ7xKTYR3DD+7mwzIaU9wldpBRf2ylgnzsqpcp2JpwEg9Ohvis7TixhaQsZWnqFHdLSldfGGWvgezqnMXhdCwQBk2zQmxho37FaH1TGLQqRBv80uV971TaL11zajukWlfIyvMY240xFquKqR2kYg6daI7pcsr6zhd6baYZNrhi8M7UQfDu+xQyFGvW9cJtHRF92yzHNrDkm+Jp7iyVrECphLgVR1UU/SiE6Pev8i5x8uUSaqT4ne+TtGF+DQBF9uHGVt5YjAcdNMEZtlW87TvVSTMmw7yfvfNuHWty+vhuPMYzapOdKekKNXLTZU13EoeNU677LDEaTYAZbtbquhzH2dScJW9InyKXRP9cs/id2iY9Y6Sb9fZttQvt94R/Cm3xKG5S0iVbQHGevBNFSaF6TRnPCxyUFNbioZaKiEe4/e9Tg/59l3uPj9pPrXEK5ZqyyYFkzY8ZVrwWWPCq3qdpsxayEmPQjxRZVvSqbbCs+pd1cm3qlombQZ5V2kDNVp0OzZnQVUrpIIiXqluJCU9yYZ4zFvmJkYOpHY+kqqUGe0iaYr5ux6D6LpT1Kc8WgyhXUW/cVH9boq6R4NIPBTgk0UX4tCNQ2qzNkZFVsgYgnvQ8BDBpke5VLUDUqQrJoa4ma0C7gL+CfAzYJu7/7GZ/QHwO8CPwqyfcff7w3NuBjYCJ4Dfd/cHyhQy1VAfDPJpAzyFYGq7jOMuvdZ22fQroTy1wvOZOE48XMl+ubs/bWZnAbuA64DfBH7q7v91aP53A18FLgMuBB4CfsHdT4x6j8Fx4l1TZOxu2wGUsqYCvIshHVPjSAFe4TjxcKX6g+H2ETPbA6wY85QNwN3ufhT4oZntpRfoM/mpxB7gMbRaqzBpmGHV1wDt4jBCXUA5TVONTjGz1cAlwBNh0sfMbLeZfcnMzgnTVgD7B562QEbom9kmM9tpZjuPcXTqgks1uhDgMH60Tl1h25VllyXmU+zKyXKHuJm9Hfg68Al3/wlwO/DzwBy9lvof9WfNePopfTbuvs3d5919fhGLpy64zKbBE1VNCufB1vesDsksq40w18ZjOrlGp5jZInoB/hV3/waAu78y8PgXgfvC3QVg1cDTVwIHKintDOhK90YVxoV0nta1lqPMgjyjUwy4A9jj7p8bmL489JcD/AbwfLi9A/ifZvY5ejs21wJPVlrqjkstyKvub+4rOx48tuU4zYm3ZpVa4dPL0xK/AvgI8JyZ9dfCzwA3mNkcva6Sl4HfBXD3F8zsHuD7wHHgpnEjUyRbFV/upgKs7vcpGuaxB3h/euxBrp2cccszOuXbZPdz3z/mObcAt5Qol1RgMBxiCrSi8p4bvAt1FckryiM2pXp1dXnEoooLSdRlUpmmvXBFV6krpZhkT4AlxaQeBqMuo9ZWeDfZZRXjBkrap5b4DKq7y6HO148xyAb77JvaP9CX+ka5T63w4tQSn1HjrgJf9nVjDNomtFHvWV3W8ia1xGfYuCCfFA7D87TR5971fv68sj4HmR1qiUumaS423MZORYVVthQ3aOpKKUchLqW01X3StdZnf4ft4F9RKQa5FKcQl5FSP7R9XBjGFPzjyli0nFV9LnUf6KNWeHkKcRkrprAbNqk1PtzFk+rBT1W10KWbtGNTOmNS106swZ3ntAKxll3ap5a4jBV7eMRevmlk1aXLB/moK6UaCnGRiPQDu8vhLdVSiMtIqYRI1wKvirqo73x2KMQlU4qhmGKZ66AAny3asSmnUBimR8E9uxTicpI2AnyWz7dShoJbIN/l2c4EvgUsDvNvd/fPmtlFwN3AUuBp4CPu/o9mthi4C/gXwN8B/9bdX66p/NIB/avbKMjHU2hLljx94keBK939YnpXtr/azNYBW4Hb3H0tcBjYGObfCBx293cCt4X5RMZSgGdr+yAfDQOM38QQ956fhruLwp8DVwLbw/Q7gevC7Q3hPuHxq8LFliVyCtI4tB3cwxTkccs1OsXMTgsXST4EPAj8AHjN3Y+HWRaAFeH2CmA/QHj8deDcjNfcZGY7zWznMY6Wq4VIg+oM11iCW9KRK8Td/YS7zwErgcuAd2XNFv5ntbr9lAnu29x93t3nF7E4b3mlZTG1ENtSxy+W2JerWuPxmmqcuLu/BnwTWAcsMbP+jtGVwIFwewFYBRAefwfw4yoKK+3Lc56PPGIOrKZpWUgZeUannAccc/fXzOwtwPvo7ax8FPgQvREqNwL3hqfsCPcfD48/4u6ntMQlPnlHiIwK8mlaqHnn7eqoFQW3VCVPS3w58KiZ7QaeAh509/uAzcAnzWwvvT7vO8L8dwDnhumfBLZUX2yJQVXn+chz9r6uhF7s3SaSnoktcXffDVySMX0fvf7x4en/AHy4ktJJ46Zt+VbRSlZLW6Q4nTtFThFjAPUPCIpVVy/cUPeVfaQ8HXYvmVK9Ck4VuhTCVVCQx00hLsmo8/B8BbekSiEutRh1zcuyFOAiJ1OIy0R5Wr95grBIF41a3iLjacem5JIVemV25E0T+oPvUcVBRgpw6RK1xCW3qsNv2tcr0ipXYEvXqSUuSckbympxy6xQS1ySo3AWeZNa4iKSSePD06AQFxFJmEJcRCRhCnERkYQpxEVEEqYQFxFJmEJcRCRhE0PczM40syfN7Fkze8HM/jBM/7KZ/dDMngl/c2G6mdkXzGyvme02s0vrroSIVE8XR05Dnpb4UeBKd78YmAOuNrN14bH/4O5z4a9/PPQ1wNrwtwm4vepCi0gz6gxyjUOvxsQQ956fhruLwt+4Cx9vAO4Kz/susMTMlpcvqoi0QS3yuOXqEzez08zsGeAQvQslPxEeuiV0mdxmZovDtBXA/oGnL4RpIiJSsVwh7u4n3H0OWAlcZma/BNwM/CLwL4GlwOYwu2W9xPAEM9tkZjvNbOcxjhYqvIg0Q63xeE01OsXdXwO+CVzt7gdDl8lR4M/gjSvfLwCrBp62EjiQ8Vrb3H3e3ecXsXj4YRGJTB1Brn7x8vKMTjnPzJaE228B3gf8db+f28wMuA54PjxlB/DRMEplHfC6ux+spfQi0ii1yOOTpyW+HHjUzHYDT9HrE78P+IqZPQc8BywD/kuY/35gH7AX+CLwe5WXWkRaoyCPy8Tzibv7buCSjOlXjpjfgZvKF01ERCbREZsiMrUqW+PqFy9HIS4ihahbJQ4KcRGRhCnERUQSphAXkcLUpdI+hbiISMIU4iIiCVOIi0gp6lJpl0JcRCRhCnERkYQpxEWkNHWptGfiuVNEROqi8C9PIS4ijVJwV0shLiKVWLP58ZEns1Jw10chLiK1UXjXTzs2RaQWCvBmKMRFpDL94FaANyd3iJvZaWb2PTO7L9y/yMyeMLOXzOxrZnZGmL443N8bHl9dT9FFJEYK8GZN0xL/OLBn4P5W4DZ3XwscBjaG6RuBw+7+TuC2MJ+IiNQgV4ib2Urg3wB/Gu4bcCWwPcxyJ70r3gNsCPcJj18V5hcRkYrlbYl/Hvg08LNw/1zgNXc/Hu4vACvC7RXAfoDw+Oth/pOY2SYz22lmO49xtGDxRURm28QQN7MPAofcfdfg5IxZPcdjb05w3+bu8+4+v4jFuQorIiInyzNO/Arg183sWuBM4Gx6LfMlZnZ6aG2vBA6E+ReAVcCCmZ0OvAP4ceUlFxGRyS1xd7/Z3Ve6+2rgeuARd/8t4FHgQ2G2G4F7w+0d4T7h8Ufc/ZSWuIiIlFdmnPhm4JNmtpden/cdYfodwLlh+ieBLeWKKCIio0x12L27fxP4Zri9D7gsY55/AD5cQdlERGQCHbEpIpIwhbiISMIU4iIiCVOIi4gkTCEuIpIwhbiISMIU4iIiCVOIi4gkzGI4It7MjgAvtl2OiiwDXm27EBVRXeKkusSp6rr8U3c/b9JMsVwo+UV3n2+7EFUws52qS3xUlzipLuWpO0VEJGEKcRGRhMUS4tvaLkCFVJc4qS5xUl1KimLHpoiIFBNLS1xERApoPcTN7Goze9HM9ppZ9BeQMLMvmdkhM3t+YNpSM3vQzF4K/88J083MvhDqttvMLm2v5Kcys1Vm9qiZ7TGzF8zs42F6cvUxszPN7EkzezbU5Q/D9IvM7IlQl6+Z2Rlh+uJwf294fHWb5R9mZqeZ2ffM7L5wP9V6vGxmz5nZM2a2M0xLbv0CMLMlZrbdzP46fGfWx1CXVkPczE4D/gS4Bng3cIOZvbvNMuXwZeDqoWlbgIfdfS3wMG9ezegaYG342wTc3lAZ8zoOfMrd3wWsA24Kyz/F+hwFrnT3i4E54GozWwdsBW4LdTkMbAzzbwQOu/s7gdvCfDH5OLBn4H6q9QD4VXefGxh+l+L6BfDHwF+6+y8CF9P7fNqvi7u39gesBx4YuH8zcHObZcpZ7tXA8wP3XwSWh9vL6Y17B/gfwA1Z88X4R+86qe9PvT7AW4GngcvpHXxx+vD6BjwArA+3Tw/zWdtlD+VZSS8QrgTuAyzFeoQyvQwsG5qW3PpF7wLxPxxetjHUpe3ulBXA/oH7C2Faai5w94MA4f/5YXoy9Qs/wy8BniDR+oQuiGeAQ8CDwA+A19z9eJhlsLxv1CU8/jq9a8XG4PPAp4GfhfvnkmY9ABz4KzPbZWabwrQU1681wI+APwvdXH9qZm8jgrq0HeKWMa1Lw2WSqJ+ZvR34OvAJd//JuFkzpkVTH3c/4e5z9FqylwHvypot/I+yLmb2QeCQu+8anJwxa9T1GHCFu19Kr3vhJjP712PmjbkupwOXAre7+yXA/2P8ReAbq0vbIb4ArBq4vxI40FJZynjFzJYDhP+HwvTo62dmi+gF+Ffc/RthcrL1AXD31+hd0HsdsMTM+qeXGCzvG3UJj78D+HGzJc10BfDrZvYycDe9LpXPk149AHD3A+H/IeDP6W1cU1y/FoAFd38i3N9OL9Rbr0vbIf4UsDbseT8DuB7Y0XKZitgB3Bhu30ivb7k//aNhT/U64PX+T68YmJkBdwB73P1zAw8lVx8zO8/MloTbbwHeR2/H06PAh8Jsw3Xp1/FDwCMeOi/b5O43u/tKd19N7/vwiLv/FonVA8DM3mZmZ/VvA78GPE+C65e7/19gv5n9szDpKuD7xFCXCHYYXAv8Db3+y//YdnlylPerwEHgGL2t7UZ6fZAPAy+F/0vDvEZv9M0PgOeA+bbLP1SXf0XvJ95u4Jnwd22K9QF+GfheqMvzwH8K09cATwJ7gf8FLA7Tzwz394bH17Rdh4w6vRe4L9V6hDI/G/5e6H+/U1y/QvnmgJ1hHfvfwDkx1EVHbIqIJKzt7hQRESlBIS4ikjCFuIhIwhTiIiIJU4iLiCRMIS4ikjCFuIhIwhTQ4JYgAAAACklEQVTiIiIJ+/9g4mm+LY0bHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "allImgCat=coco.cats\n",
    "print(len(allImgCat))\n",
    "# print(allImgCat)\n",
    "# segImg=create_datasetNch()\n",
    "# print(segImg.shape)\n",
    "createGroundTruth(0,10)\n",
    "# saveGroundTruth('test',segImg)\n",
    "dt2=loadGroundTruth('COCO_train2014_000000262145.jpg')\n",
    "dt=np.load('data/coco/ground_truth/cat/'+'COCO_train2014_000000262145.jpg.npy')\n",
    "# plt.imshow(segImg[:,:,0])\n",
    "# plt.imshow(dt[:,:,1])\n",
    "plt.imshow(dt2[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting stuffs\n",
    "\n",
    "* SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation  \n",
    "    https://arxiv.org/pdf/1511.00561.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
